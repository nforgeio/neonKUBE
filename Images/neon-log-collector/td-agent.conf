#------------------------------------------------------------------------------
# Configures the [neon-log-collector] service containers.  This service receives
# log events from the cluster nodes via [neon-log-host] and then:
#
#       * Normalizes the event records
#       * Persists them to the [neon-log-esdata] Elasticsearch cluster
#
# [neon-log-host] responsibilities
# -------------------------------------
# This runs as a Docker local container on every Docker node.  It is 
# responsible for:
#
#       1. Reading events from the systemd journal.
#       2. Receiving events from local daemons and containers
#          via syslog and tagging these with [syslog].
#       3. Receiving events from local Docker containers that
#          use the [fluentd] log driver.
#       4. Adding datacenter and node metadata to each event.
#       5. Forwarding the events to the [neon-log-collector]
#          service for filtering, normalization and persistance.
#
# [neon-log-collector] responsibilities
# -------------------------------------
# This runs as a Docker service and where most, if not all, custom
# event processing will take place.  The idea is that the [neon-log-host]
# containers are responsible for capturing events and adding a bit of 
# source and datacenter/node metadata.
#
# Then the [neon-log-collector] service handles most of the dirty work, 
# filtering, parsing, normalization, and persistence and/or forwarding 
# events for further downstream processing.  The idea behind centralizing 
# this is to make it relatively easy to customize cluster log processing.
#
# Debugging TD-Agent Configurations
# ---------------------------------
# I've found it best to manually configure one or more TD-Agent instances
# directly on a temporary cluster's node to form a pipeline and then mess
# directly with the configurations there, rather than trying to build and 
# deploy Docker containers.
#
# TD-Agent is not installed on neonCLUSTER nodes so you should run the
# following commands to install the agent and some relevant plugins:
#
#   docker service rm neon-log-collector
#   curl -4L https://toolbelt.treasuredata.com/sh/install-ubuntu-xenial-td-agent2.sh | sh
#   /usr/sbin/td-agent-gem install fluent-plugin-systemd -v 0.0.4 --no-document
#   /usr/sbin/td-agent-gem install fluent-plugin-elasticsearch --no-document
#   /usr/sbin/td-agent-gem install fluent-plugin-record-modifier --no-document
#
# You'll also have to manually patch the configurations to work by tweaking 
# the ports and addresses while debugging and copy any custom plugin Ruby
# scripts to: [/etc/td-agent/plugin/].

#------------------------------------------------------------------------------
# Receive forwarded events.

<source>    
    type    forward

    # Production settings
    bind    0.0.0.0
    port    24224

    # Debug settings
    #bind    127.0.0.2
    #port    24224
</source>

# We need to avoid capturing logs from Fluentd/TD-Agent itself to avoid 
# cascading events when there's a problem with the log pipeline.  Operators
# will need to examine the source logs to diagnose these problems.

<match fluent.**>
    @type   null
</match>

#------------------------------------------------------------------------------
# Handle neonCLUSTER Proxy events.

# NOTE: I'm hardcoding the [local7] facility here which maps to the 
#       [NeonSysLogFacility.ProxyName] constant definition.  If that
#       definition changes, you'll need to change this too.

<filter syslog.local7.**>
    @type   neon-proxy
</filter>

<filter syslog.local7.**>
    @type   neon-proxy-geoip
</filter>

#------------------------------------------------------------------------------
# Handle events from Docker containers.

<filter **>
    @type   neon-docker
</filter>

#------------------------------------------------------------------------------
# Handle events from systemd.
#
# We're going to exclude events that don't originate from a systemd service or 
# that have no message.  Then for the remaining events:
#
#       1. Set [service_type] to [systemd].
#       2. Set [service] to the service name (without the ".service" suffix).
#       3. Set [message] to the log message.
#       4. Attempt to extract the log level.
#       5. Attempt to extract a more accurate timestamp from the message.

<filter systemd.**>
    @type       grep
    regexp1     SYSTEMD_UNIT ^.*.service$
    exclude1    MESSAGE ^\s*$
</filter>

<filter systemd.**>
    @type       record_transformer
    enable_ruby

    <record>
        service_host    systemd
        service         ${/^(.*).service$/.match(record["SYSTEMD_UNIT"])[1]}
        message         ${record["MESSAGE"]}
    </record>
</filter>

<filter systemd.**>
    @type   neon-loglevel
</filter>

<filter systemd.**>
    @type   neon-timestamp
</filter>

<filter systemd.**>
    @type   neon-logfields
</filter>

#------------------------------------------------------------------------------
# Persist remaining events to the Elasticsearch cluster under the Logstash index
# after stripping out any non-whitelisted fields.
#
# Documentation: https://github.com/uken/fluent-plugin-elasticsearch

<filter **>
    @type               record_modifier
    whitelist_keys      @timestamp,cluster,container_id,datacenter,environment,level,message,module,node,node_role,service,service_host,service_type,tag,proxy,location,audit
</filter>

<match **>
    @type               elasticsearch

    # Production settings
    host                "#{ENV['NeonHosts_LogEsData']}"
    port                "#{ENV['NeonHostPorts_ProxyPrivateHttpLogEsData']}"

    # Debug settings
    #host                neon-log-esdata.cluster
    #port                5300

    logstash_format     true
    type_name           default
    include_tag_key     true
    templates           {"logstash":"/etc/td-agent/template/logstash.json"}
    time_key_format     %FT%T.%L%:z
    resurrect_after     10s

    buffer_type         memory
    buffer_chunk_limit  8m      # Maximum bytes for each buffered chuck
    buffer_queue_limit  8       # Maximum number of queued chunks
    flush_interval      1s
    disable_retry_limit
    retry_wait          1s
    max_retry_wait      15s
    num_threads         1

    # Enable these if necessary for debugging only.

    # include_tag_key     true
    # tag_key             tag
</match>
